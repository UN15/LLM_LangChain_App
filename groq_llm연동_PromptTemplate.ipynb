{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "148076c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print('Hello LangChain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2a9d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ae6c7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.\") , \n",
    "     (\"user\", \"{input}\") ] #humanìœ¼ë¡œ í•´ë„ ë¨ë¨\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"LangServeëŠ”ëŠ” ë¬´ì—‡ì¸ê°€ìš”? ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "815f9447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001DCF2D0E6C0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001DCF2D0E000> root_client=<openai.OpenAI object at 0x000001DCF2D0F770> root_async_client=<openai.AsyncOpenAI object at 0x000001DCF2D0E8A0> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "# Groq APIë¥¼ ì‚¬ìš©í•˜ëŠ” ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "llm = ChatOpenAI(\n",
    "    # api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    # model = \"mistral-saba-24b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7302a8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(response)\n",
    "    print(type(response.content))\n",
    "    print(\"ì‘ë‹µ:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aea9bd",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLMì„ Chainìœ¼ë¡œ ì—°ê²°í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37a3a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='You are an expert in AI Expert. Answer the question. <Question>: {input}ì— ëŒ€í•´ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an expert in AI Expert. Answer the question. \n",
    "    <Question>: {input}ì— ëŒ€í•´ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
    "    \"\"\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9aa7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "# chain ì—°ê²° (LCEL) prompt+llm ì—°ê²°\n",
    "chain = prompt | llm\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95482b67",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLM + OutputParserì„ Chainìœ¼ë¡œ ì—°ê²°í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a18c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# chain ì—°ê²° (LCEL) prompt + llm + outputparser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain2 = prompt | llm | output_parser\n",
    "print(type(chain2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02736518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ëŠ” ì‚¬ëŒì˜ ë‡Œê°€ í•™ìŠµí•˜ëŠ” ì›ë¦¬ì™€ ìœ ì‚¬í•©ë‹ˆë‹¤. ì»´í“¨í„°ê°€ ë°ì´í„°ë¥¼ í†µí•´ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´, ê³ ì–‘ì´ì™€ ê°•ì•„ì§€ì˜ ì‚¬ì§„ì„ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“ ë‹¤ê³  ê°€ì •í•´ ë³´ê² ìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì—ê²Œ ê³ ì–‘ì´ì™€ ê°•ì•„ì§€ì˜ ì‚¬ì§„ì„ ì—¬ëŸ¬ ì¥ ë³´ì—¬ ì£¼ê³ , ì–´ë–¤ ì‚¬ì§„ì€ ê³ ì–‘ì´, ì–´ë–¤ ì‚¬ì§„ì€ ê°•ì•„ì§€ë¼ê³  ì•Œë ¤ì¤ë‹ˆë‹¤.\n",
      "\n",
      "ëª¨ë¸ì€ ì²˜ìŒì— ê³ ì–‘ì´ì™€ ê°•ì•„ì§€ì˜ íŠ¹ì§•ì„ ëª¨ë¥´ê¸° ë•Œë¬¸ì— ì‚¬ì§„ì„ ë¶„ë¥˜í•˜ì§€ ëª»í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ì‚¬ì§„ì„ ê³„ì† ë³´ì—¬ ì£¼ê³ , ê³ ì–‘ì´ ë˜ëŠ” ê°•ì•„ì§€ë¼ê³  ì•Œë ¤ì£¼ë©´ ëª¨ë¸ì€ ì‚¬ì§„ì„ ë¶„ì„í•˜ì—¬ ê³ ì–‘ì´ì™€ ê°•ì•„ì§€ì˜ íŠ¹ì§•ì„ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.\n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´, ê³ ì–‘ì´ëŠ” ê·€ê°€ ë¾°ì¡±í•˜ê³ , ëˆˆì´ í¬ë©°, ê°•ì•„ì§€ëŠ” ê·€ê°€ ì³ì ¸ ìˆê³ , ê¼¬ë¦¬ê°€ ê¸¸ë‹¤ëŠ” ë“±ì˜ íŠ¹ì§•ì„ í•™ìŠµí•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•™ìŠµí•œ íŠ¹ì§•ì„ ë°”íƒ•ìœ¼ë¡œ ìƒˆë¡œìš´ ì‚¬ì§„ì„ ë³´ì—¬ì£¼ë©´ ëª¨ë¸ì€ ìŠ¤ìŠ¤ë¡œ ê³ ì–‘ì´ì¸ì§€ ê°•ì•„ì§€ì¸ì§€ë¥¼ ë¶„ë¥˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ í•™ìŠµ ê³¼ì •ì„ í†µí•´ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì€ ì ì  ë” ì •í™•í•˜ê²Œ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ê³  ì˜ˆì¸¡í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.\n",
      "\n",
      "êµ¬ì²´ì ìœ¼ë¡œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.\n",
      "\n",
      "1.  **ë°ì´í„° ìˆ˜ì§‘**: ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´ í•„ìš”í•œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.\n",
      "2.  **ë°ì´í„° ì „ì²˜ë¦¬**: ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ê¹¨ë—í•˜ê³ , ì¼ê´€ëœ í˜•ì‹ìœ¼ë¡œ ê°€ê³µí•©ë‹ˆë‹¤.\n",
      "3.  **ëª¨ë¸ í›ˆë ¨**: ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ ëª¨ë¸ì€ ë°ì´í„°ì˜ íŒ¨í„´ê³¼ íŠ¹ì§•ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
      "4.  **ëª¨ë¸ í‰ê°€**: í›ˆë ¨ëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì˜ ì •í™•ë„ì™€ ì‹ ë¢°ë„ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.\n",
      "5.  **ëª¨ë¸ ê°œì„ **: ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ì¶”ê°€ì ì¸ í›ˆë ¨ê³¼ í‰ê°€ë¥¼ ë°˜ë³µí•©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ ê³¼ì •ì„ í†µí•´ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì€ ë‹¤ì–‘í•œ ì‘ì—…ì— í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì´ë¯¸ì§€ ë¶„ë¥˜, ìì—°ì–´ ì²˜ë¦¬, ìŒì„± ì¸ì‹ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# chain í˜¸ì¶œ\n",
    "try:\n",
    "    result = chain.invoke({\"input\": \"ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬\"})\n",
    "    print(type(result))\n",
    "    print(result.content)\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44a2a49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "LangChainì€ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ìì—°ì–´ ì²˜ë¦¬ ë° ìƒì„± ì‘ì—…ì„ ì§€ì›í•˜ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤. LangChainì˜ ì£¼ìš” ì œí’ˆì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **LangSmith**: ë­ìŠ¤ë¯¸ìŠ¤ëŠ” ë­ì²´ì¸ í”Œë«í¼ì˜ ì¤‘ì‹¬ ì œí’ˆ ì¤‘ í•˜ë‚˜ë¡œ, ê°œë°œìê°€ ìì—°ì–´ ì²˜ë¦¬(NLP) ëª¨ë¸ì„ ì‰½ê²Œ êµ¬ì¶•, í…ŒìŠ¤íŠ¸ ë° ë°°í¬í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. ë­ìŠ¤ë¯¸ìŠ¤ë¥¼ í†µí•´ ê°œë°œìëŠ” ì‚¬ì „ êµ¬ì¶•ëœ ë‹¤ì–‘í•œ NLP ëª¨ë¸ê³¼ ì»´í¬ë„ŒíŠ¸ë¥¼ í™œìš©í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **LangChain**: ë­ì²´ì¸ì€ ìì²´ì ìœ¼ë¡œë„ í•˜ë‚˜ì˜ ì œí’ˆìœ¼ë¡œ ê°„ì£¼ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ê°œë°œìê°€ AI ëª¨ë¸ì„ ì²´ì¸ì²˜ëŸ¼ ì—°ê²°í•˜ì—¬ ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë­ì²´ì¸ì„ í†µí•´ ê°œë°œìëŠ” ë‹¤ì–‘í•œ NLP ì‘ì—…ë“¤ì„ í•˜ë‚˜ì˜ ì›Œí¬í”Œë¡œìš°ë¡œ ë§Œë“¤ì–´ íš¨ìœ¨ì ì¸ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **LangServe**: ë­ì„œë¸ŒëŠ” LangChainì—ì„œ ì œê³µí•˜ëŠ” ë˜ ë‹¤ë¥¸ ì¤‘ìš”í•œ ì œí’ˆì…ë‹ˆë‹¤. ì´ëŠ” ë­ì²´ì¸ì—ì„œ ê°œë°œëœ ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ ëª¨ë¸ì„ ì‰½ê³  ë¹ ë¥´ê²Œ ë°°í¬í•˜ê³  ê´€ë¦¬í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. ë­ì„œë¸Œë¥¼ í†µí•´ ì‚¬ìš©ìëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ëª¨ë‹ˆí„°ë§í•˜ê³ , í•„ìš”ì— ë”°ë¼ ëª¨ë¸ì„ ì—…ë°ì´íŠ¸í•˜ê±°ë‚˜ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ ì œí’ˆë“¤ì€ LangChainì´ ëª©í‘œë¡œ í•˜ëŠ” ì‚¬ìš©ì ì¹œí™”ì ì¸ AI ê°œë°œ í™˜ê²½ì˜ ì¼ë¶€ì…ë‹ˆë‹¤. LangChainì€ ê°œë°œìì™€ ê¸°ì—…ì´ AI ê¸°ìˆ ì„ ë³´ë‹¤ ì‰½ê²Œ ì ‘ê·¼í•˜ê³  í™œìš©í•  ìˆ˜ ìˆë„ë¡ ë•ê³ ì í•©ë‹ˆë‹¤.\n",
      "\n",
      "LangSmithì™€ ê°™ì€ ì œí’ˆì€ ê°œë°œìë“¤ì´ AI ëª¨ë¸ì„ ë” ì‰½ê²Œ ë§Œë“¤ê³  ê´€ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ìŒê³¼ ê°™ì€ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒìƒí•´ ë³´ì‹­ì‹œì˜¤:\n",
      "\n",
      "- ì±—ë´‡ ê°œë°œ: ë­ìŠ¤ë¯¸ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ìì—°ì–´ ì´í•´(NLU) ëª¨ë¸ì„ ì„ íƒí•˜ê³ , ì±—ë´‡ì˜ ë‹µë³€ ìƒì„±ì„ ìœ„í•œ í…œí”Œë¦¿ì„ ë§Œë“¤ê³ , ëŒ€í™” íë¦„ì„ í…ŒìŠ¤íŠ¸í•˜ê³  ë””ë²„ê¹…í•©ë‹ˆë‹¤.\n",
      "\n",
      "- ì½˜í…ì¸  ìƒì„±: ë­ì²´ì¸ì„ í™œìš©í•˜ì—¬ ê¸°ì‚¬ ì œëª©ì„ ìƒì„±í•˜ëŠ” ëª¨ë¸, ê¸°ì‚¬ ì´ˆì•ˆì„ ì‘ì„±í•˜ëŠ” ëª¨ë¸, ê·¸ë¦¬ê³  ìµœì¢…ì ìœ¼ë¡œ í¸ì§‘ ë° êµì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ì„ ì—°ê²°í•˜ì—¬ ì½˜í…ì¸  ìƒì„± ì›Œí¬í”Œë¡œìš°ë¥¼ ìë™í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ ë„êµ¬ë“¤ì€ AI ê°œë°œ ê³¼ì •ì„ ê°„ì†Œí™”í•˜ê³ , ê°œë°œìê°€ ì°½ì˜ì ì´ê³  ë³µì¡í•œ AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë³´ë‹¤ ë¹ ë¥´ê²Œ ê°œë°œí•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# chain í˜¸ì¶œ\n",
    "try:\n",
    "    result = chain2.invoke({\"input\": \"LangChainì˜ Products(ì œí’ˆ)ëŠ” ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”? ì˜ˆë¥¼ ë“¤ì–´ LangSmith ê°™ì€ Productê°€ ìˆì–´ì–´\"})\n",
    "    print(type(result))\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa937e0",
   "metadata": {},
   "source": [
    "#### Runnableì˜ stream() í•¨ìˆ˜ í˜¸ì¶œ\n",
    "### ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ìœ„í•œ ìš”ì²­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03fae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain í˜¸ì¶œ\n",
    "try:\n",
    "    answer = chain2.stream({\"input\": \"ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ ìì„¸í•˜ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\"})\n",
    "    #ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
    "    # print(answer)\n",
    "    # ìŠ¤íŠ¸ë¦¼ì—ì„œ ë°›ì€ ë°ì´í„°ì˜ ë‚´ìš©ì„ ì¶œë ¥í•©ë‹ˆë‹¤. ì¤„ë°”ê¿ˆ ì—†ì´ ì´ì–´ì„œ ì¶œë ¥í•˜ê³ , ë²„í¼ë¥¼ ì¦‰ì‹œ ë¹„ì›ë‹ˆë‹¤.\n",
    "    for token in answer:\n",
    "        print(token, end = \"\", flush = True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d5f2f2",
   "metadata": {},
   "source": [
    "### Multi Chain\n",
    "* ì²«ë²ˆì§¸ Chainì˜ ì¶œë ¥ì´, ë‘ë²ˆì§¸ Chainì˜ ì…ë ¥ì´ ëœë‹¤.\n",
    "* ë‘ ê°œì˜ Chainê³¼ Prompt+OutputParserë¥¼ LCELë¡œ ì—°ê²°í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2f289bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¥ë¥´ì— ë”°ë¼ ì˜í™” ì¶”ì²œ\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} ì¥ë¥´ì—ì„œ ì¶”ì²œí•  ë§Œí•œ í•œêµ­ ì˜í™”ë¥¼ í•œ í¸ ì•Œë ¤ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# Step 2: ì¶”ì²œëœ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ ìš”ì•½\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} ì¶”ì „í•œ ì˜í™”ì˜ ì œëª©ì„ ë¨¼ì € ì•Œë ¤ì£¼ì‹œê³ , ì¤„ì„ ë°”ê¾¸ì–´ì„œ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ 10ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì‚¬ìš©\n",
    "llm = ChatOpenAI(\n",
    "    # api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    # model = \"mistral-saba-24b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# ì²´ì¸ 1: ì˜í™” ì¶”ì²œ (ì…ë ¥: ì¥ë¥´ â†’ ì¶œë ¥: ì˜í™” ì œëª©)\n",
    "chain1 = prompt1 | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49742ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´ì¸ 2: ì¤„ê±°ë¦¬ ìš”ì•½ (ì…ë ¥: ì˜í™” ì œëª© â†’ ì¶œë ¥: ì¤„ê±°ë¦¬)\n",
    "try:\n",
    "    chain2 = (\n",
    "        {\"movie\": chain1}  # chain1ì˜ ì¶œë ¥ì„ movie ì…ë ¥ë ¥ ë³€ìˆ˜ë¡œ ì „ë‹¬\n",
    "        | prompt2\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # ì‹¤í–‰: \"SF\" ì¥ë¥´ì˜ ì˜í™” ì¶”ì²œ ë° ì¤„ê±°ë¦¬ ìš”ì•½\n",
    "    response = chain2.invoke({\"genre\": \"ì•¡ì…˜\"})\n",
    "    print(response)  \n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0247c294",
   "metadata": {},
   "source": [
    "### PromptTemplate ì—¬ëŸ¬ ê°œ ì—°ê²°í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6560e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_text = \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì„œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# PromptTemplate ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# í…œí”Œë¦¿ì— ê°’ì„ ì±„ì›Œì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ì™„ì„±\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# ë¬¸ìì—´ í…œí”Œë¦¿ ê²°í•© (PromptTemplate + PromptTemplate + ë¬¸ìì—´)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n ê·¸ë¦¬ê³  {model_name} ëª¨ë¸ì˜ ì¥ì ì„ ìš”ì•½ ì •ë¦¬í•´ ì£¼ì„¸ìš”\")\n",
    "              + \"\\n\\n {model_name} ëª¨ë¸ê³¼ ë¹„ìŠ·í•œ AI ëª¨ë¸ì€ ì–´ë–¤ ê²ƒì´ ìˆë‚˜ìš”? ëª¨ë¸ëª…ì€ {language}ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"ì˜ì–´\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    # api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    # model = \"mistral-saba-24b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"ì˜ì–´\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05e36ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 2 ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì„œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.', 'Gemma ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 3 ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì„œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.', 'llama-4 ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 4 ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì„œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.']\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì„œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# PromptTemplate ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 2},\n",
    "    {\"model_name\": \"Gemma\", \"count\": 3},\n",
    "    {\"model_name\": \"llama-4\", \"count\": 4},\n",
    "\n",
    "]\n",
    "\n",
    "# ì—¬ëŸ¬ ê°œì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë¯¸ë¦¬ ìƒì„±\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # ë¯¸ë¦¬ ìƒì„±ëœ ì§ˆë¬¸ ëª©ë¡ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6609b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 ëª¨ë¸ì€ ëŒ€ê·œëª¨ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ ì–¸ì–´ íŒ¨í„´ê³¼ êµ¬ì¡°ë¥¼ ìµíˆëŠ” ë°©ì‹ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ì£¼ì–´ì§„ ë¬¸ë§¥ ë‚´ì—ì„œ ë‹¤ìŒì— ì˜¬ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í›ˆë ¨ë˜ë©°, ì´ë¥¼ í†µí•´ ìì—°ìŠ¤ëŸ¬ìš´ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ê±°ë‚˜ ëŒ€í™”ì— ì‘ë‹µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "GemmaëŠ” ì»´í“¨í„°ê°€ ìì—°ì–´ ì²˜ë¦¬ë¥¼ ë” ì˜í•˜ë„ë¡ ì„¤ê³„ëœ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤. í…ìŠ¤íŠ¸ì˜ í†µê³„ì  íŒ¨í„´ì„ í•™ìŠµí•˜ì—¬ ë¬¸ì¥ êµ¬ì¡°, ë‹¨ì–´ ì˜ë¯¸ ë° ë§¥ë½ì„ ì´í•´í•©ë‹ˆë‹¤. ì´ í•™ìŠµì„ í†µí•´ GemmaëŠ” ì§ˆë¬¸ì— ë‹µë³€í•˜ê³ , í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•˜ê³ , ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë“± ë‹¤ì–‘í•œ ì–¸ì–´ ê´€ë ¨ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "LLama-4 ëª¨ë¸ì€ Metaì—ì„œ ê°œë°œí•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ìˆ˜ì‹­ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©°, ë°©ëŒ€í•œ ì–‘ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ ìì—°ì–´ ì²˜ë¦¬ ëŠ¥ë ¥ì„ ìŠµë“í•©ë‹ˆë‹¤. LLaMA-4ì˜ í•™ìŠµ ì›ë¦¬ëŠ” ì£¼ì–´ì§„ ë¬¸ë§¥ì—ì„œ ë‹¤ìŒì— ì˜¬ ê°€ëŠ¥ì„±ì´ ë†’ì€ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ëŠ” ìê¸° ì§€ë„ í•™ìŠµ ë°©ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ LLaMA-4ëŠ” ë‹¤ì–‘í•œ ìì—°ì–´ ì²˜ë¦¬ ì‘ì—…ì— í™œìš©ë  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ì–¸ì–´ ì´í•´ ëŠ¥ë ¥ì„ ê°œë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    # api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    # model = \"mistral-saba-24b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    response = llm.invoke(prompt) # AIMessage\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2423c82",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate \n",
    "* SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aafea846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "**ë”¥ëŸ¬ë‹**ì€ ì¸ê³µì‹ ê²½ë§ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤. ë”¥ëŸ¬ë‹ì€ ë°ì´í„°ë¡œë¶€í„° ê³„ì¸µì ì¸ íŒ¨í„´ì„ í•™ìŠµí•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. \n",
      "\n",
      "ë”¥ëŸ¬ë‹ì€ ì‚¬ëŒì˜ ë‡Œ êµ¬ì¡°ë¥¼ ëª¨ë°©í•œ ì¸ê³µì‹ ê²½ë§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ ì¸ê³µì‹ ê²½ë§ì€ ì—¬ëŸ¬ ê°œì˜ ë ˆì´ì–´ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ê° ë ˆì´ì–´ëŠ” ì…ë ¥ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì—¬ ë‹¤ìŒ ë ˆì´ì–´ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê³¼ì •ì„ í†µí•´ ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ ë°ì´í„°ì˜ íŒ¨í„´ì„ í•™ìŠµí•˜ê³ , ì˜ˆì¸¡ì´ë‚˜ ë¶„ë¥˜ì™€ ê°™ì€ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë”¥ëŸ¬ë‹ì˜ í•µì‹¬ ê°œë…ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "* **ì¸ê³µì‹ ê²½ë§**: ì‚¬ëŒì˜ ë‡Œ êµ¬ì¡°ë¥¼ ëª¨ë°©í•œ ëª¨ë¸ë¡œ, ì—¬ëŸ¬ ê°œì˜ ë ˆì´ì–´ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
      "* **ë ˆì´ì–´**: ì¸ê³µì‹ ê²½ë§ì„ êµ¬ì„±í•˜ëŠ” ê¸°ë³¸ ë‹¨ìœ„ë¡œ, ì…ë ¥ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì—¬ ë‹¤ìŒ ë ˆì´ì–´ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
      "* **í™œì„±í™” í•¨ìˆ˜**: ê° ë ˆì´ì–´ì—ì„œ ì¶œë ¥ê°’ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ë¡œ, sigmoid, ReLU ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "* **ì†ì‹¤ í•¨ìˆ˜**: ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” í•¨ìˆ˜ë¡œ, ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
      "* **ìµœì í™” ì•Œê³ ë¦¬ì¦˜**: ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, SGD, Adam ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë”¥ëŸ¬ë‹ì€ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì´ë¯¸ì§€ ì¸ì‹, ìì—°ì–´ ì²˜ë¦¬, ìŒì„± ì¸ì‹, ììœ¨ ì£¼í–‰ ìë™ì°¨ ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ê°œë³„ ë©”ì‹œì§€ í…œí”Œë¦¿ ì •ì˜\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"ë‹¹ì‹ ì€ {topic} ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ëª…í™•í•˜ê³  ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplateë¡œ ë©”ì‹œì§€ë“¤ì„ ë¬¶ê¸°\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# ë©”ì‹œì§€ ìƒì„±\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"ë”¥ëŸ¬ë‹ì€ ë¬´ì—‡ì¸ê°€ìš”?\")\n",
    "\n",
    "# LLM í˜¸ì¶œ\n",
    "llm = ChatOpenAI(\n",
    "    # api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    # model = \"mistral-saba-24b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c73a971",
   "metadata": {},
   "source": [
    "### FewShotPromptTemplate\n",
    "* ì˜ˆì‹œë¥¼ ì œê³µ í”„ë¡¬í”„íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a9802c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### íƒœì–‘ê³„ì˜ í–‰ì„±\n",
      "1. **ìˆ˜ì„±**: ê°€ì¥ ì‘ì€ í–‰ì„±ìœ¼ë¡œ íƒœì–‘ê³¼ ê°€ê¹ìŠµë‹ˆë‹¤.\n",
      "2. **ê¸ˆì„±**: ë°ê³  ëœ¨ê±°ìš´ í–‰ì„±ì…ë‹ˆë‹¤.\n",
      "3. **ì§€êµ¬**: ìƒëª…ì²´ê°€ ì‚¬ëŠ” ìœ ì¼í•œ í–‰ì„±ì…ë‹ˆë‹¤.\n",
      "4. **í™”ì„±**: ë¶‰ì€ í–‰ì„±ìœ¼ë¡œ ë¡œë´‡ íƒì‚¬ê°€ í™œë°œí•©ë‹ˆë‹¤.\n",
      "5. **ëª©ì„±**: íƒœì–‘ê³„ì—ì„œ ê°€ì¥ í° í–‰ì„±ì…ë‹ˆë‹¤.\n",
      "6. **í† ì„±**: ì•„ë¦„ë‹¤ìš´ ê³ ë¦¬ë¥¼ ê°€ì§„ í–‰ì„±ì…ë‹ˆë‹¤.\n",
      "7. **ì²œì™•ì„±**: ìì „ì¶•ì´ ê¸°ìš¸ì–´ì§„ í–‰ì„±ì…ë‹ˆë‹¤.\n",
      "8. **í•´ì™•ì„±**: ê°€ì¥ ë¨¼ í–‰ì„±ìœ¼ë¡œ ë§¤ìš° ì¶¥ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.\",\n",
    "        \"output\": \"\"\"### ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™\n",
    "1. **ê´€ì„±ì˜ ë²•ì¹™**: í˜ì´ ì‘ìš©í•˜ì§€ ì•Šìœ¼ë©´ ë¬¼ì²´ëŠ” ê³„ì† ê°™ì€ ìƒíƒœë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\n",
    "2. **ê°€ì†ë„ì˜ ë²•ì¹™**: ë¬¼ì²´ì— í˜ì´ ì‘ìš©í•˜ë©´, í˜ê³¼ ì§ˆëŸ‰ì— ë”°ë¼ ê°€ì†ë„ê°€ ê²°ì •ë©ë‹ˆë‹¤.\n",
    "3. **ì‘ìš©-ë°˜ì‘ìš© ë²•ì¹™**: ëª¨ë“  í˜ì—ëŠ” í¬ê¸°ê°€ ê°™ê³  ë°©í–¥ì´ ë°˜ëŒ€ì¸ í˜ì´ ì‘ìš©í•©ë‹ˆë‹¤.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"ì§€êµ¬ì˜ ëŒ€ê¸° êµ¬ì„± ìš”ì†Œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\",\n",
    "        \"output\": \"\"\"### ì§€êµ¬ ëŒ€ê¸°ì˜ êµ¬ì„±\n",
    "- **ì§ˆì†Œ (78%)**: ëŒ€ê¸°ì˜ ëŒ€ë¶€ë¶„ì„ ì°¨ì§€í•©ë‹ˆë‹¤.\n",
    "- **ì‚°ì†Œ (21%)**: ìƒëª…ì²´ê°€ í˜¸í¡í•˜ëŠ” ë° í•„ìš”í•©ë‹ˆë‹¤.\n",
    "- **ì•„ë¥´ê³¤ (0.93%)**: ë°˜ì‘ì„±ì´ ë‚®ì€ ê¸°ì²´ì…ë‹ˆë‹¤.\n",
    "- **ì´ì‚°í™”íƒ„ì†Œ (0.04%)**: ê´‘í•©ì„± ë° ì˜¨ì‹¤ íš¨ê³¼ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# ì˜ˆì œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate ì ìš©\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ê³¼í•™ êµìœ¡ìì…ë‹ˆë‹¤.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ìƒì„± ë° ì²´ì¸ êµ¬ì„±\n",
    "# model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "model = ChatOpenAI(\n",
    "    # api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    # model = \"mistral-saba-24b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "chain = final_prompt | model\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "result = chain.invoke({\"input\": \"íƒœì–‘ê³„ì˜ í–‰ì„±ë“¤ì„ ê°„ëµíˆ ì •ë¦¬í•´ ì£¼ì„¸ìš”.\"})\n",
    "#result = chain.invoke({\"input\": \"ì–‘ì ì–½í˜ì´ ë¬´ì—‡ì¸ê°€ìš”?\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8ea266",
   "metadata": {},
   "source": [
    "### PartialPromptTemplate\n",
    "* í”„ë¡¬í”„íŠ¸ì˜ ì…ë ¥ ê°’ì— í•¨ìˆ˜ í˜¸ì¶œ ì´ë‚˜ ì™¸ë¶€ APIë¥¼ í˜¸ì¶œí•œ ë™ì ì¸ ê°’ì„ ëŒ€ì…í•  ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821d2539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ê³„ì ˆ: ê²¨ìš¸\n",
      "ğŸ”¹ í”„ë¡¬í”„íŠ¸: input_variables=['season'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['season'], input_types={}, partial_variables={}, template='{season}ì— ì£¼ë¡œ ë°œìƒí•˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒ 3ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. ê° í˜„ìƒì— ëŒ€í•´ ê°„ë‹¨í•œ ì„¤ëª…ì„ í¬í•¨í•´ì£¼ì„¸ìš”.'), additional_kwargs={})]\n",
      "ğŸ”¹ ëª¨ë¸ ì‘ë‹µ: ê²¨ìš¸ì— ë°œìƒí•˜ëŠ” ìì—° í˜„ìƒ : \n",
      " ê²¨ìš¸ì— ì£¼ë¡œ ë°œìƒí•˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒ 3ê°€ì§€ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "1.  **ê·¹ê´‘**: ê·¹ê´‘ì€ íƒœì–‘ì—ì„œ ë°©ì¶œëœ í•˜ì „ ì…ìë“¤ì´ ì§€êµ¬ ìê¸°ì¥ì— ì´ëŒë ¤ ê·¹ì§€ë°©ì—ì„œ ëŒ€ê¸° ë¶„ìì™€ ì¶©ëŒí•˜ì—¬ ë°œìƒí•˜ëŠ” í˜„ìƒì…ë‹ˆë‹¤. í•˜ëŠ˜ì´ í™”ë ¤í•œ ìƒ‰ìœ¼ë¡œ ë¬¼ë“¤ì–´ ì•„ë¦„ë‹µê²Œ ë¹›ë‚˜ëŠ” í˜„ìƒì…ë‹ˆë‹¤. ì£¼ë¡œ ë¶ê·¹ê³¼ ë‚¨ê·¹ ì§€ì—­ì—ì„œ ë³¼ ìˆ˜ ìˆìœ¼ë©°, ê²¨ìš¸ì— íŠ¹íˆ ë§ì´ ë°œìƒí•©ë‹ˆë‹¤.\n",
      "2.  **ë¹™í•˜**: ë¹™í•˜ëŠ” ê·¹ì§€ë°©ì´ë‚˜ ê³ ì‚° ì§€ì—­ì—ì„œ ë°œìƒí•˜ëŠ” í˜„ìƒìœ¼ë¡œ, ëˆˆì´ ìŒ“ì—¬ ì••ì¶•ë˜ì–´ ì–¼ì–´ë¶™ì€ ê²ƒì„ ë§í•©ë‹ˆë‹¤. ë¹™í•˜ëŠ” ì§€êµ¬ì˜ ê¸°í›„ ë³€í™”ë¥¼ ë°˜ì˜í•˜ëŠ” ì¤‘ìš”í•œ ì§€í‘œ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ê²¨ìš¸ì— ë¹™í•˜ì˜ í¬ê¸°ê°€ ì¦ê°€í•˜ê³ , ì—¬ë¦„ì— ë¹™í•˜ì˜ í¬ê¸°ê°€ ê°ì†Œí•˜ëŠ” í˜„ìƒì´ ë°˜ë³µë©ë‹ˆë‹¤.\n",
      "3.  **í•´ë¹™**: í•´ë¹™ì€ ê·¹ì§€ë°©ì˜ ë°”ë‹¤ì—ì„œ ë°œìƒí•˜ëŠ” í˜„ìƒìœ¼ë¡œ, ê²¨ìš¸ì— ë°”ë‹¤ì— ì–¼ìŒì´ ì–¼ê³  ì—¬ë¦„ì— ì–¼ìŒì´ ë…¹ëŠ” ê²ƒì„ ë§í•©ë‹ˆë‹¤. í•´ë¹™ì€ ì§€êµ¬ì˜ ê¸°í›„ ë³€í™”ë¥¼ ë°˜ì˜í•˜ëŠ” ì¤‘ìš”í•œ ì§€í‘œ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. í•´ë¹™ì˜ ë³€í™”ëŠ” í•´ì–‘ ìƒíƒœê³„ì™€ ì§€êµ¬ì˜ ê¸°í›„ì— í° ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# ê³„ì ˆì„ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ (ë‚¨ë°˜êµ¬/ë¶ë°˜êµ¬ ê³ ë ¤)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "    \n",
    "    if hemisphere == \"north\":  # ë¶ë°˜êµ¬ (ê¸°ë³¸ê°’)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ë´„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ì—¬ë¦„\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ê°€ì„\"\n",
    "        else:\n",
    "            return \"ê²¨ìš¸\"\n",
    "    else:  # ë‚¨ë°˜êµ¬ (ê³„ì ˆ ë°˜ëŒ€)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ê°€ì„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ê²¨ìš¸\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ë´„\"\n",
    "        else:\n",
    "            return \"ì—¬ë¦„\"\n",
    "        \n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ (ë¶€ë¶„ ë³€ìˆ˜ ì ìš©)\n",
    "\n",
    "# prompt = PromptTemplate(\n",
    "#     template=\"{season}ì— ì¼ì–´ë‚˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒì€ {phenomenon}ì…ë‹ˆë‹¤.\",\n",
    "#     input_variables=[\"phenomenon\"],  # ì‚¬ìš©ì ì…ë ¥ í•„ìš”\n",
    "#     partial_variables={\"season\": get_current_season(\"south\")}  # ë™ì ìœ¼ë¡œ ê³„ì ˆ ê°’ í• ë‹¹\n",
    "# )\n",
    "\n",
    "season = get_current_season(\"south\")\n",
    "print(f\"í˜„ì¬ ê³„ì ˆ: {season}\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"{season}ì— ì£¼ë¡œ ë°œìƒí•˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒ 3ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. \"\n",
    "    \"ê° í˜„ìƒì— ëŒ€í•´ ê°„ë‹¨í•œ ì„¤ëª…ì„ í¬í•¨í•´ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "#model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "# íŠ¹ì • ê³„ì ˆì˜ í˜„ìƒ ì§ˆì˜\n",
    "chain = (\n",
    "    {\"season\": lambda x: season}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "result = chain.invoke({})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ğŸ”¹ í”„ë¡¬í”„íŠ¸: {prompt}\")\n",
    "print(f\"ğŸ”¹ ëª¨ë¸ ì‘ë‹µ: {season}ì— ë°œìƒí•˜ëŠ” ìì—° í˜„ìƒ : \\n {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13af7f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=[] input_types={} partial_variables={'info': '1ë‹¬ëŸ¬ = 1365.14ì›'} template='í˜„ì¬ {info} ê¸°ì¤€ìœ¼ë¡œ í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. í˜„ì¬ í™˜ìœ¨ì„ ê¸°ì¤€ìœ¼ë¡œ í•œêµ­ê²½ì œ ë¯¸ì¹˜ëŠ” ì˜í–¥ ë° í–¥í›„ì— í™˜ìœ¨ì˜ ì˜ˆìƒê°’ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”.'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ì‹¤ì‹œê°„ í™˜ìœ¨ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1ë‹¬ëŸ¬ = {data['rates']['KRW']}ì›\"\n",
    "\n",
    "# {info} ë³€ìˆ˜ì— APIì—ì„œ ë°›ì€ í™˜ìœ¨ ì •ë³´ë¥¼ ë™ì ìœ¼ë¡œ ë°˜ì˜\n",
    "prompt = PromptTemplate(\n",
    "    template=\"í˜„ì¬ {info} ê¸°ì¤€ìœ¼ë¡œ í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. í˜„ì¬ í™˜ìœ¨ì„ ê¸°ì¤€ìœ¼ë¡œ í•œêµ­ê²½ì œ ë¯¸ì¹˜ëŠ” ì˜í–¥ ë° í–¥í›„ì— í™˜ìœ¨ì˜ ì˜ˆìƒê°’ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”.\",\n",
    "    input_variables=[],  # ì‚¬ìš©ì ì…ë ¥ ì—†ìŒ\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # APIì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„° ìë™ ë°˜ì˜\n",
    ")\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ec92092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ í”„ë¡¬í”„íŠ¸: í˜„ì¬ 1ë‹¬ëŸ¬ = 1365.14ì› ê¸°ì¤€ìœ¼ë¡œ í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. í˜„ì¬ í™˜ìœ¨ì„ ê¸°ì¤€ìœ¼ë¡œ í•œêµ­ê²½ì œ ë¯¸ì¹˜ëŠ” ì˜í–¥ ë° í–¥í›„ì— í™˜ìœ¨ì˜ ì˜ˆìƒê°’ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”.\n",
      "ğŸ”¹ ëª¨ë¸ ì‘ë‹µ: ## í•œêµ­ ê²½ì œì— ë¯¸ì¹˜ëŠ” ì˜í–¥\n",
      "\n",
      "1. **ìˆ˜ì¶œ ì¦ê°€**: ì•½í•œ ì›í™” ê°€ì¹˜ëŠ” í•œêµ­ì˜ ìˆ˜ì¶œì„ ì´‰ì§„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìˆ˜ì¶œì—…ì²´ëŠ” ë‹¬ëŸ¬ë¡œ ê²°ì œí•˜ëŠ” ìˆ˜ì¶œ ëŒ€ê¸ˆì„ ì›í™”ë¡œ í™˜ì‚°í•  ë•Œ ë” ë§ì€ ì›í™”ë¥¼ ë°›ì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, ìˆ˜ì¶œëŸ‰ì´ ì¦ê°€í•˜ê³  ê¸°ì—…ì˜ ìˆ˜ìµì„±ì´ ê°œì„ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ê²½ì œ ì„±ì¥ì— ê¸ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ë¬¼ê°€ ìƒìŠ¹**: ì›í™” ì•½ì„¸ëŠ” ìˆ˜ì… ë¬¼ê°€ë¥¼ ìƒìŠ¹ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìˆ˜ì… ì›ìì¬, ì—ë„ˆì§€, ì‹í’ˆ ë“±ì˜ ê°€ê²©ì´ ìƒìŠ¹í•˜ë©´ êµ­ë‚´ ë¬¼ê°€ì—ë„ ì˜í–¥ì„ ë¯¸ì³ ì¸í”Œë ˆì´ì…˜ì„ ì´ˆë˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ê°€ê³„ì˜ êµ¬ë§¤ë ¥ì„ ê°ì†Œì‹œí‚¤ê³ , ì†Œë¹„ë¥¼ ìœ„ì¶•ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **ê¸°ì—…ì˜ ë¶€ë‹´ ì¦ê°€**: ì›í™” ì•½ì„¸ëŠ” ê¸°ì—…, íŠ¹íˆ ìˆ˜ì…ì— ì˜ì¡´í•˜ëŠ” ê¸°ì—…ë“¤ì—ê²Œ ë¶€ë‹´ì„ ê°€ì¤‘ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì›ìì¬, ë¶€í’ˆ ë“±ì„ ìˆ˜ì…í•  ë•Œ ë” ë§ì€ ì›í™”ë¥¼ ì§€ë¶ˆí•´ì•¼ í•˜ê¸° ë•Œë¬¸ì—, ìƒì‚° ë¹„ìš©ì´ ì¦ê°€í•˜ê³  ìˆ˜ìµì„±ì´ ê°ì†Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. **ì™¸êµ­ì¸ íˆ¬ì ê°ì†Œ**: ì›í™” ì•½ì„¸ëŠ” ì™¸êµ­ì¸ íˆ¬ììë“¤ì—ê²Œ í•œêµ­ ì‹œì¥ì— ëŒ€í•œ íˆ¬ì ë§¤ë ¥ì„ ê°ì†Œì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. íˆ¬ììë“¤ì€ í™˜ìœ¨ ë³€ë™ì— ë”°ë¥¸ ìœ„í—˜ì„ ê³ ë ¤í•˜ì—¬, ì•ˆì •ì ì¸ ìˆ˜ìµì„ ê¸°ëŒ€í•  ìˆ˜ ìˆëŠ” ë‹¤ë¥¸ ì‹œì¥ìœ¼ë¡œ ìê¸ˆì„ ì´ë™ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "## í–¥í›„ í™˜ìœ¨ ì˜ˆìƒ\n",
      "\n",
      "1. **ê¸€ë¡œë²Œ ê²½ì œ ìƒí™©**: ë¯¸êµ­ì˜ í†µí™” ì •ì±…, ì£¼ìš”êµ­ì˜ ê²½ì œ ìƒí™©, êµ­ì œ ë¬´ì—­ ê´€ê³„ ë“±ì´ ì›ë‹¬ëŸ¬ í™˜ìœ¨ì— í° ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ë¯¸êµ­ ì—°ë°©ì¤€ë¹„ì œë„(Fed)ì˜ ê¸ˆë¦¬ ì¸ìƒì´ë‚˜ ê¸€ë¡œë²Œ ê²½ê¸° ì¹¨ì²´ ìš°ë ¤ê°€ ì›ë‹¬ëŸ¬ í™˜ìœ¨ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **í•œêµ­ ê²½ì œ ì§€í‘œ**: í•œêµ­ì˜ ê²½ì œ ì„±ì¥ë¥ , ë¬¼ê°€ ìƒìŠ¹ë¥ , ë¬´ì—­ ìˆ˜ì§€ ë“± ê²½ì œ ì§€í‘œë“¤ì´ í™˜ìœ¨ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ê²½ì œê°€ ì•ˆì •ì ì´ê³  ì„±ì¥í•  ê²½ìš° ì›í™” ê°€ì¹˜ê°€ ìƒìŠ¹í•  ìˆ˜ ìˆê³ , ê²½ì œê°€ ë¶ˆì•ˆí•˜ê±°ë‚˜ ì„±ì¥ë¥ ì´ ë‚®ì„ ê²½ìš° ì›í™” ê°€ì¹˜ê°€ í•˜ë½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **ì›ìœ  ê°€ê²©**: êµ­ì œ ì›ìœ  ê°€ê²©ì˜ ë³€ë™ë„ í™˜ìœ¨ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ì›ìœ  ìˆ˜ì…ì— ì˜ì¡´í•˜ëŠ” í•œêµ­ì€ ì›ìœ  ê°€ê²© ìƒìŠ¹ ì‹œ ì›í™” ì•½ì„¸ê°€ ë‚˜íƒ€ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. **ì •ì±…ì  ìš”ì¸**: í•œêµ­ì€í–‰ê³¼ ì •ë¶€ì˜ ê²½ì œ ì •ì±…ë„ í™˜ìœ¨ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ê¸ˆë¦¬ ì¡°ì •, ì™¸í™˜ ì‹œì¥ ê°œì…, ì¬ì • ì •ì±… ë“±ì´ ì›í™” ê°€ì¹˜ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "í˜„ì¬ í™˜ìœ¨ 1ë‹¬ëŸ¬ = 1365.14ì›ì€ ë‹¤ì–‘í•œ ê²½ì œì  ìš”ì¸ì— ì˜í•´ ë³€ë™í•  ìˆ˜ ìˆìœ¼ë©°, í–¥í›„ í™˜ìœ¨ ì „ë§ì€ ë¶ˆí™•ì‹¤í•©ë‹ˆë‹¤. ê²½ì œ ìƒí™©, ì •ì±… ë³€í™”, ê¸€ë¡œë²Œ ì´ë²¤íŠ¸ ë“± ë‹¤ì–‘í•œ ìš”ì¸ì„ ê³ ë ¤í•˜ì—¬ ì‹ ì¤‘í•˜ê²Œ ë¶„ì„í•´ì•¼ í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LLM ëª¨ë¸ ì„¤ì • (GPT-4o-mini ì‚¬ìš©)\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.5\n",
    ")\n",
    "# ëª¨ë¸ì— í”„ë¡¬í”„íŠ¸ ì „ë‹¬ ë° ì‘ë‹µ ë°›ê¸°\n",
    "response = model.invoke(prompt.format())\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ğŸ”¹ í”„ë¡¬í”„íŠ¸:\", prompt.format())\n",
    "print(\"ğŸ”¹ ëª¨ë¸ ì‘ë‹µ:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
