{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c18aa37d",
   "metadata": {},
   "source": [
    "### 문제 7-1 : LangGraph ReAct Agent 실습 연습문제 (Vector DB + Tool 연동) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cc1a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from textwrap import dedent\n",
    "import warnings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama  import OllamaEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from typing import List\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embeddings_model = OllamaEmbeddings(model=\"bge-m3:latest\") \n",
    "\n",
    "# menu db 벡터 저장소 로드\n",
    "menu_db = FAISS.load_local(\n",
    "    \"../db/cafe_db\", \n",
    "    embeddings_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# Tool 정의 \n",
    "@tool\n",
    "def search_menu(query: str) -> List[str]:\n",
    "    \"\"\"카페 메뉴에서 정보를 검색합니다.\"\"\"\n",
    "    docs = menu_db.similarity_search(query, k=6)\n",
    "\n",
    "    formatted_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document source=\"{doc.metadata[\"source\"]}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if len(docs) > 0:\n",
    "        return formatted_docs\n",
    "    \n",
    "    return \"관련 메뉴 정보를 찾을 수 없습니다.\"\n",
    "\n",
    "\n",
    "\n",
    "# Tool 정의 \n",
    "@tool\n",
    "def search_web(query: str) -> List[str]:\n",
    "    \"\"\"데이터베이스에 존재하지 않는 정보 또는 최신 정보를 인터넷에서 검색합니다.\"\"\"\n",
    "\n",
    "    tavily_search = TavilySearchResults(max_results=3)\n",
    "    docs = tavily_search.invoke(query)\n",
    "\n",
    "    formatted_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if len(docs) > 0:\n",
    "        return formatted_docs\n",
    "    \n",
    "    return \"관련 정보를 찾을 수 없습니다.\"\n",
    "\n",
    "\n",
    "# LLM 모델 \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", streaming=True)\n",
    "\n",
    "# llm = ChatOpenAI(\n",
    "#     base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "#     model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "#     temperature=0.2\n",
    "# )\n",
    "\n",
    "# 도구 목록\n",
    "tools = [search_menu, search_web]\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "system_prompt = dedent(\"\"\"\n",
    "당신은 사용자 질문에 답변하는 카페 AI 어시스턴트입니다.  \n",
    "제공된 도구들을 활용해 정확한 정보를 전달해야 합니다.\n",
    "\n",
    "[작동 원칙]\n",
    "1. 질문 이해: 사용자의 질문을 정확히 파악하세요\n",
    "2. 도구 활용: 필요한 정보는 반드시 제공된 도구로 조회\n",
    "3. 출처 명시: 도구 사용 후 즉시 아래 형식으로 출처 표기\n",
    "4. 최종 답변은 질문과 직접 관련된 명확한 내용으로 구성하고, 불필요한 정보는 포함하지 마세요.\n",
    "\n",
    "\n",
    "[도구 사용 형식]\n",
    "액션: 도구_이름  \n",
    "액션 입력: 도구에_넘길_입력값  \n",
    "\n",
    "[출처 표기 형식]\n",
    "[출처: 도구_이름 | 문서_제목/항목명 | URL/파일경로]\n",
    "\n",
    "[예시 1 - 메뉴 검색]\n",
    "액션: search_menu  \n",
    "액션 입력: 아메리카노  \n",
    "\n",
    "(도구 실행 후)  \n",
    "[출처: search_menu | 아메리카노 | ../data/cafe_menu_data.txt]  \n",
    "아메리카노 정보: 아메리카노 4,500원...\n",
    "\n",
    "[예시 2 - 웹 검색]  \n",
    "액션: search_web  \n",
    "액션 입력: AI 역사  \n",
    "\n",
    "(도구 실행 후)  \n",
    "[출처: search_web | AI 역사 | https://ko.wikipedia.org/wiki/인공지능]  \n",
    "AI 역사는 1950년대부터...\n",
    "\n",
    "[주의사항]\n",
    "1. 도구가 필요없는 질문은 직접 답변\n",
    "2. 모든 사실 정보는 반드시 출처 동반\n",
    "3. 출처 없이는 어떠한 정보도 제공하지 말 것\n",
    "4. 최종 답변은 질문과 직접 관련된 명확한 내용으로 구성하고, 불필요한 정보는 포함하지 마세요.\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "class GraphState(MessagesState):\n",
    "    pass\n",
    "\n",
    "# 노드 구성 \n",
    "def call_model(state: GraphState):\n",
    "    messages = state['messages']\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "tool_node = ToolNode(tools=tools)\n",
    "\n",
    "# 그래프 구성\n",
    "builder = StateGraph(GraphState)\n",
    "builder.add_node(\"agent\", call_model)\n",
    "builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "builder.add_edge(START, \"agent\")\n",
    "builder.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b8a1efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 아메리카노 비교 ---\n",
      "아메리카노와 아이스 아메리카노는 기본적인 재료는 동일하지만, 제공되는 온도에 따라 큰 차이가 있습니다.\n",
      "\n",
      "1. **아메리카노**:\n",
      "   - 가격: 4,500원\n",
      "   - 종류: 에스프레소와 뜨거운 물로 만들어집니다.\n",
      "\n",
      "2. **아이스 아메리카노**:\n",
      "   - 가격: 4,500원\n",
      "   - 종류: 에스프레소와 차가운 물, 그리고 얼음으로 만들어집니다.\n",
      "\n",
      "결론적으로 두 음료의 가격은 동일하지만, 아메리카노는 뜨거운, 아이스 아메리카노는 차가운 형태로 판매됩니다. \n",
      "\n",
      "[출처: search_menu | 아메리카노 | ../data/cafe_menu_data.txt]  \n",
      "[출처: search_menu | 아이스 아메리카노 | ../data/cafe_menu_data.txt]\n",
      "\n",
      "--- 라떼 종류 문의 ---\n",
      "라떼 종류에는 다음과 같은 메뉴가 있습니다:\n",
      "\n",
      "1. **카페라떼**\n",
      "   - 가격: ₩5,500\n",
      "   - 주요 원료: 에스프레소, 스팀 밀크\n",
      "   - 설명: 진한 에스프레소에 부드럽게 스팀한 우유를 넣어 만든 대표적인 밀크 커피입니다. 크리미한 질감과 부드러운 맛이 특징이며, 다양한 시럽과 토핑 추가가 가능합니다.\n",
      "\n",
      "2. **바닐라 라떼**\n",
      "   - 가격: ₩6,000\n",
      "   - 주요 원료: 에스프레소, 스팀 밀크, 바닐라 시럽\n",
      "   - 설명: 카페라떼에 달콤한 바닐라 시럽을 더한 인기 메뉴입니다. 바닐라의 달콤함과 커피의 쌉싸름함이 조화롭게 어우러지며, 휘핑크림 토핑으로 풍성한 맛을 즐길 수 있습니다.\n",
      "\n",
      "3. **녹차 라떼**\n",
      "   - 가격: ₩5,800\n",
      "   - 주요 원료: 말차 파우더, 스팀 밀크, 설탕\n",
      "   - 설명: 고급 말차 파우더와 부드러운 스팀 밀크로 만든 건강한 음료입니다. 녹차의 은은한 쓴맛과 우유의 부드러움이 조화를 이루며, 항산화 성분이 풍부합니다.\n",
      "\n",
      "4. **카라멜 마키아토**\n",
      "   - 가격: ₩6,500\n",
      "   - 주요 원료: 에스프레소, 스팀 밀크, 카라멜 시럽, 휘핑크림\n",
      "   - 설명: 스팀 밀크 위에 에스프레소를 부어 만든 후 카라멜 시럽과 휘핑크림으로 마무리한 달콤한 커피입니다. 카라멜의 진한 단맛과 커피의 깊은 맛이 조화를 이룹니다.\n",
      "\n",
      "각 메뉴는 독특한 맛과 풍미를 제공하므로 취향에 맞는 메뉴를 선택해 즐기시면 좋습니다.\n",
      "\n",
      "[출처: search_menu | 라떼 종류 | ../data/cafe_menu_data.txt]\n",
      "\n",
      "--- 디저트 문의 ---\n",
      "티라미수는 다음과 같은 특성을 가진 디저트입니다:\n",
      "\n",
      "- **가격**: ₩7,500\n",
      "- **주요 원료**: 마스카포네 치즈, 에스프레소, 레이디핑거, 코코아 파우더\n",
      "- **설명**: 이탈리아 전통 디저트로, 마스카포네 치즈와 에스프레소에 적신 레이디핑거를 층층이 쌓아 만든 것입니다. 부드럽고 달콤한 맛이 특징이며, 코코아 파우더로 마무리하여 깊은 풍미를 자랑합니다.\n",
      "\n",
      "[출처: search_menu | 티라미수 | ../data/cafe_menu_data.txt]\n",
      "\n",
      "--- 일반적인 질문 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9292\\389995913.py:53: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily_search = TavilySearchResults(max_results=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph는 LangChain에서 개발한 오픈 소스 AI 에이전트 프레임워크입니다. 이 프레임워크는 복잡한 생성적 AI 에이전트 워크플로우를 구축, 배포 및 관리하기 위한 도구와 라이브러리를 제공합니다. LangGraph는 그래프 기반 아키텍처를 사용하여 인공지능 워크플로우를 보다 효율적으로 모델링하고 관리할 수 있게 해줍니다.\n",
      "\n",
      "주요 특징은 다음과 같습니다:\n",
      "- 상태를 유지하는 오케스트레이션 프레임워크로, 에이전트 기반 애플리케이션에 사용됩니다.\n",
      "- 대규모 언어 모델(LLMs)을 효과적으로 운영할 수 있는 인프라를 제공합니다.\n",
      "- 복잡한 관계를 모델링하여 AI 에이전트의 의사결정을 향상시킵니다.\n",
      "\n",
      "이 프레임워크는 대화형 에이전트, 복잡한 작업 자동화 및 사용자 경험을 지원하는 LLM 기반 솔루션을 구축할 수 있는 기반을 제공합니다.\n",
      "\n",
      "[출처: search_web | langgraph | https://www.ibm.com/think/topics/langgraph]\n"
     ]
    }
   ],
   "source": [
    "# 테스트 시나리오\n",
    "print(\"--- 아메리카노 비교 ---\")\n",
    "inputs_1 = {\"messages\": [SystemMessage(content=system_prompt), HumanMessage(content=\"아메리카노와 아이스 아메리카노의 차이점과 가격을 알려주세요.\")]}\n",
    "messages_1 = graph.invoke(inputs_1)\n",
    "for m in messages_1['messages']:\n",
    "    if isinstance(m, AIMessage) and not m.tool_calls and m.content:\n",
    "        print(m.content)\n",
    "\n",
    "print(\"\\n--- 라떼 종류 문의 ---\")\n",
    "inputs_2 = {\"messages\": [SystemMessage(content=system_prompt), HumanMessage(content=\"라떼 종류에는 어떤 메뉴들이 있고 각각의 특징은 무엇인가요?\")]}\n",
    "messages_2 = graph.invoke(inputs_2)\n",
    "for m in messages_2['messages']:\n",
    "    if isinstance(m, AIMessage) and not m.tool_calls and m.content:\n",
    "        print(m.content)\n",
    "\n",
    "print(\"\\n--- 디저트 문의 ---\")\n",
    "inputs_3 = {\"messages\": [SystemMessage(content=system_prompt), HumanMessage(content=\"디저트 메뉴 중에서 티라미수에 대해 자세히 설명해주세요.\")]}\n",
    "messages_3 = graph.invoke(inputs_3)\n",
    "for m in messages_3['messages']:\n",
    "    if isinstance(m, AIMessage) and not m.tool_calls and m.content:\n",
    "        print(m.content)\n",
    "\n",
    "# 도구가 필요 없는 질문 예시\n",
    "print(\"\\n--- 일반적인 질문 ---\")\n",
    "inputs_4 = {\"messages\": [SystemMessage(content=system_prompt), HumanMessage(content=\"langgraph란?\")]}\n",
    "messages_4 = graph.invoke(inputs_4)\n",
    "for m in messages_4['messages']:\n",
    "    if isinstance(m, AIMessage) and not m.tool_calls and m.content:\n",
    "        print(m.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
